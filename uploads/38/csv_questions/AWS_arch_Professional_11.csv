Question,Option1,Option2,Option3,Option4,Option5,Option6,"Correct Option
(Note:- if correct option is Option1 then insert 1)",Category Name,Marks
"You are responsible for a web application that consists of an Elastic Load Balancer (ELB) in
front of an Auto Scaling group of Amazon Elastic Compute Cloud (EC2) instances. For a
recent deployment of a new version of the application, a new Amazon Machine Image
(AMI) was created, and the Auto Scaling group was updated with a new launch
configuration that refers to this new AMI. During the deployment, you received complaints
from users that the website was responding with errors. All instances passed the ELB
health checks. What should you do in order to avoid errors for future deployments?
(Choose 2 answers)","Add an Elastic Load Balancing health check to the Auto Scaling group. Set a
short period for the health checks to operate as soon as possible in order to
prevent premature registration of the instance to the load balancer.","Enable EC2 instance CloudWatch alerts to change the launch configuration
AMI to the previous one. Gradually terminate instances that are using the
new AMI.","Set the Elastic Load Balancing health check configuration to target a
part of the application that fully tests application health and returns an
error if the tests fail.","Create a new launch configuration that refers to the new AMI, and
associate it with the group. Double the size of the group, wait for the
new instances to become healthy, and reduce back to the original size.
If new instances do not become healthy, associate the previous launch
configuration.","Increase the Elastic Load Balancing Unhealthy Threshold to a higher value
to prevent an unhealthy instance from going into service behind the load
balancer",,3&4,AWS Archi Professional,5
"You have deployed a web application targeting a global audience across multiple AWS
Regions under the domain name example.com. You decide to use Route53 Latency-Based
Routing to serve web requests to the users from the region closest to them. To provide
business continuity in the event of server downtime you configure weighted record sets
associated with two web servers in separate Availability Zones per region.
During a DR test you notice that when you disable all web servers in one of the regions
Route53 does not automatically direct all users to the other region. What could be
happening? (Choose 2 answers)","Latency resource record sets cannot be used in combination with weighted
resource record sets.","You did not setup an HTTP health check to one or more of the
weighted resource record sets associated with the disabled web
servers.","The value of the weight associated with the latency alias resource record
set in the region with the disabled servers is higher than the weight for the
other region","One of the two working web servers in the other region did not pass its
HTTP health check.","You did not set “Evaluate Target Health” to “Yes” on the latency alias
resource record set associated with example.com in the region where
you disabled the servers",,2&5,AWS Archi Professional,5
"Using an Amazon linux AMI, you have created a m5.large EC2 instance for one of your
research programs. Due to limited budget, you prefer to put the instance into a stopped
state when it is not used. However one requirement is that when the status of instance
becomes running from stopped, the instance does not reboot and you can continue from
where it left off. You want to hibernate the EC2 instance to make this happen. Which
description is correct to implement this hibernation option?","You cannot enable hibernation on an existing instance. You have to
relaunch a new instance from an instance store volume so that the the
hibernation option is supported","You can use AWS console to select the instance, and choose Actions,","You cannot enable hibernation on an existing instance. You have to
launch a new instance with a HVM AMI. Enable the hibernation feature
on the Configure Instance Details page","You can only use AWS CLI to enable the hibernation option via “aws ec2
hibernate-instances --instance-ids i-1234567890abcdef0”. AWS Console is
not supported for the hibernation option",,,3,AWS Archi Professional,5
"You currently operate a web application in the AWS US-East region. The application runs
on an auto-scaled layer of EC2 instances and an RDS Multi-AZ database. Your IT security
compliance officer has tasked you to develop a reliable and durable logging solution to
track changes made to your EC2, IAM and RDS resources. The solution must ensure the
integrity and confidentiality of your log data. Which of the below solutions would you
recommend?","Create a new CloudTrail trail with one new S3 bucket to store the logs
and with the option that applies trail to all regions selected. Use IAM
roles, S3 bucket policies and Multi Factor Authentication (MFA) to
delete on the S3 bucket that stores your logs.","Instance State, Stop - Hibernate","Create a new CloudTrail trail with an existing S3 bucket to store the logs
and with the option that applies trail to all regions selected. Use S3 ACLs
and Multi Factor Authentication (MFA) to delete on the S3 bucket that
stores your logs","Create three new CloudTrail trails with three new S3 buckets to store the
logs one for the AWS Management console, one for AWS SDKs and one for
command line tools. Use IAM roles and S3 bucket policies on the S3
buckets that store your logs",,,1,AWS Archi Professional,5
"Your company has landed a contract to build a search engine of public legal documents.
The dataset is of around 150TB in size and available at customer’s data center in various
formats, part of the dataset is stored in tapes and other is stored in disks. Some of the
dataset is very old, dated to nearly 15 years back, and stored in the compressed format to
save on the disk space. The management has assigned you the task to come up with a
flexible and cost-efficient design to ingest these data and make it available for the frontend
application to efficiently search through. Select two valid options.",Use the Snowball to migrate the data to S3,"Use the AWS Batch to process the data from S3 and send to Kinesis
Firehose and finally save to AWS ElasticSearch",Setup a VPN connection and transfer the data to AWS S3 over the weekend,"Load the data to EFS and create Auto Scaling EC2 instances to read
through the data and save into the AWS RDS for querying","Use the Direct Connect to transfer the data from on-premise servers to the
S3",,1&2,AWS Archi Professional,5
"A company has setup a Direct Connect connection between their on-premise location and
their AWS VPC. They want to setup redundancy in case the Direct Connect connection
fails. What can they do in this regard?
Choose 2 options from the below:",Setup another Direct Connect connection.,Setup an IPSec VPN Connection,Setup S3 connection,Setup a connection via EC2 instances.,,,1&2,AWS Archi Professional,5
"You are designing a photo-sharing mobile app. The application will store all pictures in a
single Amazon S3 bucket. Users will upload pictures from their mobile device directly to
Amazon S3 and will be able to view and download their own pictures directly from
Amazon S3. You want to configure security to handle potentially millions of users in the
most secure manner possible.
What should be done by your server-side application, when a new user registers on the
photo-sharing mobile application?","Create a set of long-term credentials using AWS Security Token Service
with appropriate permissions. Store these credentials in the mobile app
and use them to access Amazon S3.","Record the user’s Information in Amazon RDS and create a role in IAM
with appropriate permissions. When the user uses their mobile app
create temporary credentials using the AWS Security Token Service
‘AssumeRole’ function, store these credentials in the mobile app’s
memory and use them to access Amazon S3. Generate new
credentials the next time the user runs the mobile app.","Record the user’s Information In Amazon DynamoDB. When the user uses
their mobile app create temporary credentials using AWS Security Token
Service with appropriate permissions. Store these credentials in the mobile
app’s memory and use them to access Amazon S3. Generate new
credentials the next time the user runs the mobile app","Create IAM user. Assign appropriate permissions to the IAM user Generate
an access keyand secret key for the IAM user, store them in the mobile app
and use thesecredentials to access Amazon S3.","Create an IAM user. Update the bucket policy with appropriate permissions
for the IAM user. Generate an access Key and secret Key for the IAM user,
store them in the mobile app and use these credentials to access Amazon
S3.",,2,AWS Archi Professional,5
"Your company is storing millions of sensitive transactions across thousands of 100-GB files
that must be encrypted in-transit and at-rest. Analysts concurrently depend on subsets of
files, which can consume up to 5 TB of space, to generate simulations that can be used to
steer business decisions. You are required to design an AWS solution that can cost
effectively accommodate the long-term storage and in-flight subsets of data. Which one
would you choose?","Use Amazon Simple Storage Service (S3) with server-side encryption, and
run simulations on subsets in ephemeral drives on Amazon EC2.","Use Amazon S3 with server-side encryption, and run simulations on
subsets in-memory on Amazon EC2.","Use HDFS on Amazon EMR, and run simulations on subsets in ephemeral
drives on Amazon EC2.","Use HDFS on Amazon Elastic MapReduce (EMR), and run simulations
on subsets in-memory on Amazon Elastic Compute Cloud (EC2).","Store the full data set in encrypted Amazon Elastic Block Store (EBS)
volumes, and regularly capture snapshots that can be cloned to EC2
workstations.",,4,AWS Archi Professional,5
"Your company has built a Therapist Finder service. Since the launch last year, there are
over 150K therapists registered from around the country and the service is growing
rapidly. The management has decided to add a new much-needed feature to showcase
Verified Therapists on their website so that when users search for related therapists the
service can show the verified therapists. Their current database is in DynamoDB. The
management is ready to do some reengineering if the solution can be cost effective as
well. Select two options to accommodate the new feature and also optimize the costing","Stream the DynamoDB data to ElasticSearch using AWS Lambda and
use it for the search",Use the ElasticSearch queries to boost the search result efficiently ,Migrate the DynamoDB data to AWS RDS database and use it for the search,"Use the AWS ElastiCache in front of the DynamoDB to cache the search
results","Use the DynamoDB Accelerator to execute complex queries and save the
read capacity",,2,AWS Archi Professional,5
"As an IT administrator, you have been requested to manage the CloudFormation stacks for
a set of developers in your company. A set of web and database developers will be
working on the application. How would you design the CloudFormation stacks in the best
way possible?","CloudFormation is not the right fit, use OpsWork instead.",Create one stack for the web and database developers.,Create separate stacks for the web and database developers.,"Define separate EC2 instances since defining CloudFormation can get
cumbersome",,,3,AWS Archi Professional,5
"Your company policies require encryption of sensitive data at rest. You are considering the
possible options for protecting data while storing it at rest on an EBS data volume,
attached to an EC2 instance. Which of these options would allow you to encrypt your data
at rest?
Choose 3 options from the below",Implement third party volume encryption tools,Do nothing as EBS volumes are encrypted by default,Encrypt data inside your applications before storing it on EBS,"Encrypt data using native data encryption drivers at the file system
level",Implement SSL/TLS for all services running on the server,,"1,3&4",AWS Archi Professional,5
"You require the ability to analyze a customer’s clickstream data on a website so they can
do the behavioral analysis. Your customer needs to know what sequence of pages and
ads their customer clicked on. This data will be used in real time to modify the page
layouts as customers click through the site to increase stickiness and advertising clickthrough.
Which option meets the requirements for captioning and analyzing this data?","Log clicks in weblogs by URL and store it in Amazon S3, and then analyze
with Elastic MapReduce","Push web clicks by session to Amazon Kinesis and analyze behavior
using Kinesis workers",Write click events directly to Amazon Redshift and then analyze with SQL,"Publish web clicks by session to an Amazon SQS queue and periodically
drain these events to Amazon RDS and analyze with sql.",,,2,AWS Archi Professional,5
"To follow the new security compliances your company has hired an external auditor to
assess the security perimeter around your SaaS platform. The application is running in
multiple regions and uses the load balancers within each regions for higher availability.
The instances loads sensitive configurations from an S3 bucket at start and the DynamoDB
is used as primary database. The auditor has advised to further tighten the security groups
and NACLs based on the application requirement and use the private network instead of
using the public endpoints to access the AWS services. Your team decided to use the VPC
Endpoints as it uses the AWS internal network for all the communication, after detail
examination they realised the current architecture will not allow them to use the VPC
endpoints as it is and will require a set of modifications. Please select three valid
modifications:","Configure the DynamoDB Global Tables to replicate the data into
multi-regions","Create VPC Endpoints for S3 and DynamoDB and modify the route
tables for all the availability zones used by the auto scaling group","Use the NAT Gateway for all the egress communication to these AWS
services","Setup VPC gateway endpoint for S3 and interface endpoint for DynamoDB
to communicate with these services over the private AWS network","Use the S3 Cross Region Replication to save the configurations in the
multiple regions",,"1,2&5",AWS Archi Professional,5
"Your organization is planning to shift one of the high-performance data analytics
application running on Linux servers purchased from the 3rd party vendor to the AWS.
Currently, the application works in an on-premise load balancer and all the data is stored
in a very large shared file system for low-latency and high throughput purpose. The
management wants minimal disruption to existing service and also wants to do stepwise
migration for easy rollback. Please select valid options from below","Save all the data on S3 and use it as shared storage, use an application load
balancer with EC2 instances to share the processing load","Create a RAID 1 storage using EBS and run the application on EC2 with
application-level load balancers to share the processing load","Use the VPN or Direct Connect to create a link between your company
premise and AWS regional data center","Create an EFS with provisioned throughput and share the storage
between your on-premise instances and EC2 instances","Setup a Route 53 record to distribute the load between on-premise
and AWS load balancer with the weighted routing policy",,"3,4&5",AWS Archi Professional,5
"You work for an AWS consulting company and are required to provide a cost control for a
customer’s AWS resources. This customer has owned various applications which have
used over 100 DynamoDB tables. For the below cases, which ones should you consider
using On Demand capacity for DynamoDB? Select 3.","New applications whose DynamoDB database workload is very
complex to forecast","An application has large spikes sometimes however with very short
duration","A long term monitor program that has stable read/write traffic for a
DynamoDB table","The read/write throughput for a DynamoDB database is quite steady in
weekdays and getting a 20% increase in weekends.",An application with serverless stacks with pay-per-use pricing model.,,"1,2&5",AWS Archi Professional,5
"A customer is hosting their company website on a cluster of web servers that are behind a
public-facing load balancer. The customer also uses Amazon Route 53 to manage their
public DNS. How should the customer configure the DNS zone apex record to point to the
load balancer?",Create an A record pointing to the IP address of the load balancer,Create a CNAME record pointing to the load balancer DNS name,Create a CNAME record aliased to the load balancer DNS name.,Create an alias record that points to your load balancer,,,4,AWS Archi Professional,5
"By default, when an EBS volume is attached to a Windows instance, it may show up as any
drive letter on the instance. Which of the following services can be used to change the
settings of the drive letters of the EBS volumes as per your specifications?",EBSConfig Service,AMIConfig Service,EC2Config,EC2-AMIConfig Service,,,3,AWS Archi Professional,5
"You are designing the network infrastructure for an application server in Amazon VPC.
Users will access all the application instances from the Internet as well as from an onpremises
network. The on-premises network is connected to your VPC over an AWS
Direct Connect link. How would you design routing to meet the above requirements?","Configure a single routing table with a default route via the Internet
gateway. Propagate a default route via BGP on the AWS Direct Connect
customer router. Associate the routing table with all VPC subnets.","Configure a single routing table with a default route via the Internet
gateway. Propagate specific routes for the on-premises networks via
BGP on the AWS Direct Connect customer router. Associate the
routing table with all VPC subnets.","Configure a single routing table with two default routes: one to the Internet
via an Internet gateway the other to the on-premises network via the VPN
gateway. Use this routing table across all subnets in your VPC.","Configure two routing tables: one that has a default route via the Internet
gateway, and another that has a default route via the VPN gateway.
Associate both routing tables with each VPC subnet.",,,2,AWS Archi Professional,5
"You are a development lead and your team has maintained an emailing service for the
company’s major applications. The emailing service is deployed on-premise with several
RDS on VMware databases to store users’ metadata. There is no plan to migrate the onpremise
RDS databases to AWS RDS. However you need an appropriate approach to
backup the databases to AWS so that the database can be quickly restored. Which steps
should you take to fulfill this requirement? (Select THREE)","Specify an automated backup every day to store the snapshot to S3
bucket so that the backup has high availability and durability","Configure a read-replica in the same region as the VPC that the RDS on
VMware instance connects to. Read-replica cannot be created in other
regions","Create an automated backup schedule in RDS and save the daily snapshots
to AWS Glacier for long term backup","Create a read-replica in additional region for disaster recovery as long
as the region supports RDS","Create backups by replicating the RDS on-premise instance to RDS in
AWS.",,"1,4&5",AWS Archi Professional,5
"Your team is building up a smart home iOS APP. The end users have used your company’s
camera-equipped home devices such as baby monitors, webcams, and home surveillance
systems. Then the videos are uploaded to AWS Kinesis. Afterwards, through the mobile
APP, users can play the on-demand or live videos using the format of HTTP Live
Streaming (HLS). Which combinations of steps should you use accomplish this task?
(Select TWO)","Create a Kinesis Data Firehose to ingest, durably store and encrypt the live
videos from the users’ home devices","Create a Kinesis video stream to capture, store, and index the videos
from the camera-equipped home devices.","Transform the stream data to HLS compatible data by using Kinesis Data
Analytics or customer code in EC2/Lambda. Then in the mobile application,
use HLS protocol to display the video stream by using the converted HLS
streaming data.","In the mobile application, use HLS to display the video stream by using
the HLS streaming session URL",,,2&4,AWS Archi Professional,5
"An IOT company has a new product which is a camera device. The device has installed
several sensors and can record video as required. The device has AWS Kinesis Video
Streams SDK in the software and is able to transmit recorded video in real time to AWS
Kinesis. Then the end users can use a desktop or web client to view, download or share
the video stream. The client app should be simple and use a third-party player such as
Google Shaka Player to display the video stream from Kinesis. How should the client app
be designed?","The client can use HTTP Live Streaming (HLS) for live playback. Use
GetMedia API to process and play Kinesis video streams.","The client can use HLS for live playback. Use
GetHLSStreamingSessionURL API to retrieve the HLS streaming
session URL then provide the URL to the video player","The client can use Adobe HTTP Dynamic Streaming (HDS) for live playback.
Use GetHDSStreamingSessionURL API to retrieve the HDS streaming
session URL then provide the URL to the video player","The client can use Microsoft Smooth Streaming (MSS) for live playback.
Use GetMSSStreaming API to retrieve the MSS streaming to the video
player.",,,2,AWS Archi Professional,5
"You are hired as an AWS solutions architect in a startup company. You notice that there
are some issues for the backup strategy of EC2 instances and there is no snapshot
lifecycle management at all. Users just create snapshots manually without a routine policy
to control. You want to suggest to use a proper EBS Snapshot Lifecycle policy. How would
you persuade your team lead to approve this suggestion? (Select TWO)","A snapshot lifecycle policy helps to retain backups as required by
auditors or internal compliance","An EBS Snapshot Lifecycle helps to protect valuable data by enforcing
a regular backup schedule","A proper snapshot lifecycle policy is able to reduce storage costs as the
snapshots taken by the schedule policy are free","User can design their own schedule to backup snapshots according to
different requirements, such as every 1 week, 2 weeks etc",,,1&2,AWS Archi Professional,5
"A communication company has deployed several EC2 instances in region ap-southeast-1
which are used to monitor user activities. The AWS administrator has configured an EBS
lifecycle policy to create a snapshot every day for each EBS volume to preserve data. The
retention is configured as 5 which means the oldest snapshot will be deleted after 5 days.
The administrator plans to copy some snapshots to another region ap-southeast-2 as
these snapshots contain some important data. Are these new snapshots in the new region
retained with this method?","These new snapshots may be deleted after the retention period as they are
still affected by the retention policy.","These new snapshots can be kept only when they are copied to another
region otherwise they may be deleted by the retention policy. In this case,
the snapshots can be kept","These new snapshots can be kept as the retention schedule is not
carried over to the copy","The new snapshots in region ap-southeast-2 will be deleted after 5 days
unless the delete protection option is enabled",,,3,AWS Archi Professional,5
"An IT company has a big data analytics application that is deployed in EC2 in multiple
availability zones. These EC2 instances simultaneously access a shared Amazon EFS file
system using a traditional file permissions model. A recent internal security audit has
found that there is a potential security risk as the EFS file system is not encrypted for
either at rest or in transit. What actions could be taken to address the potential security
threat posed by non encryption of the EFS volume?","The encryption of data at rest has to be enabled when the Amazon
EFS file system is created. The encryption of data in transit can be
enabled when the file system is mounted in EC2 instance","The encryption of data at rest and in transit can be enabled when the
Amazon EFS file system is created","The encryption of data at rest and in transit can only be enabled when the
Amazon EFS file system is mounted in EC2 instance.","The encryption of data at rest is able to be enabled when the Amazon EFS
file system is mounted in EC2 instance. The encryption of data in transit is
enabled when the EFS file system is created using AWS console or CLI.",,,1,AWS Archi Professional,5
"For application development and testing purpose, your team has created several EFS
volumes recently. You, as the AWS operation engineer, have been assigned a task to
mount these EFS file systems to EC2 linux instances with encryption enabled in transit.
You have already installed the EFS mount helper in the instances. To use the mount
helper properly to mount the EFS volumes, which actions should you perform? (Select
THREE)","Get that EFS file system's ID from the console or programmatically
through the Amazon EFS API","Make sure that the security group of EC2 instances has opened the port 443
for SSL traffic","In your virtual private cloud (VPC) availability zones of EC2 instances,
mount targets are needed to be created first for EFS volumes","In the EC2’s subnets, create a rule in network ACL to allow HTTPS traffic so
that encryption in transit between EC2 and EFS file system is allowed","When the mount helper utility is used, add the encryption option which
is “-o tls”.",,"1,3&5",AWS Archi Professional,5
"You are an AWS consultant in an IT company. Your development manager just assigned
you a task to evaluate if the EBS volume types of the EC2 instances were properly
configured in all regions. The major concern that you have found is that almost all EBS
volumes are using the Provisioned IOPS SSD (io1) volume type which costs the company a
lot. You plan to change the volume type from io1 to other types. However, for which
scenarios should you still use the EBS volume type of io1?","A boot volume of a test server which is frequently used by the Quality
Assurance team.","A Cassandra database which needs extremely low latency and high
performance when being processed.","A data warehouse server that contains huge amount of customer data. The
data needs to be accessed and analyzed by a monitor process frequently","Some large and legacy cold data which is stored to trace customers’
activities in the past. The database requires fewer scans per day.",,,2,AWS Archi Professional,5
"An AWS Solutions Architect has noticed that their company is using almost exclusively
EBS General Purpose SSD (gp2) volume types for their EBS volumes. They are considering
modifying the type of some of these volumes, but it is important that performance is not
affected. Which of the following actions could the Solutions Architect consider? (Select
TWO)","A 50GB gp2 root volume can be modified to an EBS Provisioned IOPS
SSD (io1) without stopping the instance.","A gp2 volume that is attached to an instance as a root volume needs can be
modified to a Throughput Optimized HDD (st1) volume.","A 1GB gp2 volume that is attached to an instance as a non-root volume can
be modified to a Cold HDD (sc1) volume","A 1TB gp2 volume that is attached to an instance as a non-root volume
can be modified to a Throughput Optimized HDD (st1) volume without
stopping the instance or detaching the volume",,,1&4,AWS Archi Professional,5
"You work in a video game company and your team is working on a feature that tells how
many times that certain web pages have been viewed or clicked. You also created an
AWS Lambda function to show some key statistics of the data. You tested the Lambda
function and it worked perfectly.
However, your team lead requires you to show the statistics every day at 8:00AM GMT on
a big TV screen so that when employees come in to the office every morning, they have a
rough idea of how the feature runs. What is the most cost efficient and straightforward
way for you to make this happen?","Create an AWS CloudWatch Events rule that is scheduled using a cron
expression as “00 08 * * ? *”. Configure the target as the Lambda
function","Create an Amazon linux EC2 T2 instance and set up a Cron job using
Crontab. Use AWS CLI to call your AWS Lambda every 8:00AM.","Use Amazon Batch to set up a job with a job definition that runs every
8:00AM for the Lambda function","In AWS CloudWatch Events console, click “Create Event” using the cron
expression “ * ? * * 08 00”. Configure the target as the Lambda function",,,1,AWS Archi Professional,5
"A company has its major business on selling second-hand products and its online trading
system is deployed on AWS EC2 instances. In Route53, a domain name has been
configured to route the traffic to a Classic Load Balancer. As Classic Load Balancer is quite
old and in AWS there are new types of Load Balancers which Classic Load Balancer can
be easily migrated to, the operation team decides to migrate the Load Balancer. They
want all the connections between clients and EC2 instances be kept secure using
certificates that they created and also want a secure data encryption in transit between
the clients and EC2 instances. Which choices should be used together to meet the needs?
Select 2 Options","In “Create Load Balancer” console, create an Application Load Balancer and
add a listener with protocol TLS and port 443 so that the TLS connections
terminate at the Load Balancer.","Go to the Load Balancer console, create a Network Load Balancer with
a listener that listens to the traffic with protocol as TLS and port as 443","Create an Application Load Balancer with a listener that listens to the traffic
with protocol as HTTPS and port 80.","For the new Load Balancer, select the target protocol as HTTPS and port as
443, which set up the connections with targets securely","For the new Load Balancer, select the target protocol as TLS and port
as 443. As a result, the connections between Load Balancer and
targets are secure",,2&5,AWS Archi Professional,5
"Which of the following can be done by Auto scaling?
Choose 2 answers from the options given below:",Launch EC2 instances when CPU utilization is above the threshold,Terminate EC2 instances when CPU utilization is below the threshold,Increase the instance size when utilization is above the threshold.,Decrease the instance size when utilization is below the threshold,,,1&2,AWS Archi Professional,5
"You are an AWS administrator. Your company has two key EC2 instances owned by AWS
account A. The users in AWS account B may start/stop these EC2 instances from time to time. These users are under the same IAM user group called “Group_QA”. You already
created an across AWS accounts role “EC2Update” in account A.
And in account B, “Group_QA” has been added an inline policy to assume the role of
“EC2Update”. After users in AWS account B login in, which approaches are valid for these
users to switch to the role “EC2Update” in account A? (Select TWO)","With AWS CLI, the user calls the AssumeRoleWithSAML function to obtain
credentials for the “EC2Update” role.","The user chooses the account name on the navigation bar and clicks
“Switch Role”. The user specifies the account ID (or alias) and role
name","The user can click on a link sent in email by the administrator which
takes the user to the Switch Role page with the details already filled in.
The link can be found when the role “EC2Update” was created","In AWS console, the user clicks its account name and chooses “Switch
Accounts”. The user then specifies the account ID, key credentials and the
role name for account A.",,,2&3,AWS Archi Professional,5
"Your company is running a premium photo-sharing application. Users can upload their
creative photos and license them to be used by others. The application allows the users to
watermark and do other signatures before the images can be visible to everyone in the
public stream. The watermarking and signature is based on the user selected plan and
allows to do a certain number of images in a given timeframe. Along with this, the company has collaboration with some users and groups, and they are allowed to process
images faster compared to others whenever they submit their images.
The application is currently saving the images into S3 when uploaded and from there it
generates the Lambda trigger to process the images. However, the application is not able
to manage the different pipeline of work and need some ordered processing. The
management has decided to re-engineer the application to effectively support the above
requirements.","Use SQS queues instead of Lambda Trigger. Use the priority order
messages to process the images","Save the processing information to DynamoDB before saving the image to
S3. When the AWS Lambda trigger runs, pull the information from
DynamoDB and process accordingly","Use two SQS queues instead of Lambda Trigger. One with high priority
messages and another for the low priority messages. Check for the
messages into the high priority queue before processing any
messages from the low priority queue","Use the AWS Batch to create jobs with priority job queues and use the
combination of EC2 On-Demand and Spot instances to process the
messages",,,3,AWS Archi Professional,5
"A user has created a VPC with CIDR 20.0.0.0/16. The user has created one subnet with
CIDR 20.0.0.0/16 in this VPC. The user is trying to create another subnet with the same
VPC for CIDR 20.0.0.0/24. What will happen in this scenario?",It will throw a CIDR overlap error,It is not possible to create a subnet with the same CIDR as the VPC,The second subnet will be created,The VPC will modify the first subnet to allow this IP range,,,1,AWS Archi Professional,5
"Currently, a company uses Redshift to store its analyzed data. They have started with the
base configuration. What would they get when they initially start using Redshift?",Two nodes with 320GB each,One node of 320GB,2 Nodes with 160 GB each,One node of 160GB,,,3,AWS Archi Professional,5
"Your company has developed a Serverless web and mobile application which allows
users to upload and monetize video courses. The application is using the API Gateway and
Lambda as the front-end stack and uses MongoDB as the database, all the video content
is stored in the S3 and served via the CloudFront. The MongoDB is hosted outside of the
AWS environment as a 3rd party database service. After the initial launch, the company
started receiving the performance related issues for some of their popular courses.
The operations team runs an uplink monitor to make sure the database is connected and
bandwidth is optimal. The management has decided to run some analytics to check how
each request from web or mobile is performing in real-time and how much time is allotted
to the database. Please suggest the steps to create the analytics report and how to
improve the overall performance of the application with minimal efforts. Select 3 Options","Use the DynamoDB instead of the MongoDB as it provides better scalability
and performance.","Migrate the MongoDB from outside of the AWS to inside the AWS. This
will reduce the additional latency required to connect with the
database from the AWS environment","Integrate the AWS X-Ray and create a segment around the MongoDB
connections to measure actual latency per requests","Use ElastiCache to cache the popular or frequently used courses data
to reduce the interaction with the database","Use the AWS SQS in-front of the database connection to decouple the
application with direct database connectivity.",,"2,3&4",AWS Archi Professional,5
"A startup company has developed its on-premise SAAS product using standard
Kubernetes. Kubernetes has proved to be a success because of its feature of easily
deploying and managing containerized applications at scale. The R&D team also gained
adequate Kubernetes experiences including related tools such as kubectl. Recently, the
CTO of the company has proposed to migrate the whole product to AWS platform. How
should they design the migration with the least code modification?","Provision and run Kubernetes on powerful EC2 instance types such as c5
so that the Kubernetes deployment is fully managed.","Run Kubernetes in Amazon Elastic Container Service for Kubernetes
(EKS) without needing to provision or manage master instances","In Amazon ECR, store, encrypt, and manage container images for fast
deployment. Manage and run Kubernetes clusters in Amazon Elastic
Container Service (ECS).","Configure and run Kubernetes in AWS Fargate without having to manage
servers or clusters",,,2,AWS Archi Professional,5
"A company has an application that is hosted on an EC2 instance. The code is written
in .NET and connects to a MySQL RDS database. If you're executing .NET code against
AWS on an EC2 instance that is assigned an IAM role, which of the following is a true
statement?
Choose the correct option from the below:",The code will assume the same permissions as the EC2 role,The code must have AWS access keys in order to execute,Only .NET code can assume IAM roles,None of the above,,,1,AWS Archi Professional,5
"A company is making extensive use of S3. They have a strict security policy and require
that all artifacts are stored securely in S3. Which of the following request headers, when
specified in an API call, will cause an object to be SSE?
Choose the correct option from the below",AES256,amz-server-side-encryption,x-amz-server-side-encryption,server-side-encryption,,,3,AWS Archi Professional,5
"One of your requirements is to setup an S3 bucket to store your files like documents and
images. However, those objects should not be directly accessible via the S3 URL, they
should only be accessible from pages on your website so that only your paying customers
can see them. How could you implement this?
Choose the correct option from the below:",Use HTTPS endpoints to encrypt your data.,"You can use a bucket policy and check for the AWS: Referer key in a
condition, where that key matches your domain",You can't. The S3 URL must be public in order to use it on your website,"You can use server-side and client-side encryption, where only your
application can decrypt the objects",,,2,AWS Archi Professional,5
"A big trading company requires various organizations such as importers, exporters, banks,
shipping companies, and customs departments, to work with one another. The traderelated
paperwork need to go back and forth between the stakeholders, taking 5-10 days
to complete, which is very time-consuming. The company is considering creating a
blockchain network where all parties can transact and process trade-related paperwork
electronically without the need for a central trusted authority.
For the below descriptions, which ones help the company understand AWS Managed
Blockchain service? Choose 3","Amazon Managed Blockchain can easily scale the blockchain network
as the usage of applications on the network grows over time","Amazon Managed Blockchain eliminates the need for manually
provisioning hardware, configuring software, and setting up
networking and security components.","Amazon Managed Blockchain charges a upfront fee and requires a
commitment for a 12 months usage.","Popular blockchain frameworks including Hyperledger Fabric, Ethereum,
R3 Corda are supported in most regions","Once a new member is added, Managed Blockchain lets that member
launch and configure multiple blockchain peer nodes. A",,"1,2&5",AWS Archi Professional,5
"You are having trouble maintaining session states on some of your applications that are
using an Elastic Load Balancer(ELB). There does not seem to be an even distribution of
sessions across your ELB. Which of the following is the quickest method by AWS to try
and rectify the issues to overcome this problem that you are having?
Choose the correct option from the below:","Disable Sticky session. Use Elasticache to put session data.
Elasticache is easy to set up, manage and scale a distributed inmemory
cache environment in the cloud","Use a special cookie to track the instance for each request to each listener.
When the load balancer receives a request, it will then check to see if this
cookie is present in the request","Use the sticky session feature (also known as session affinity), which
enables the load balancer to bind a user's session to a specific instance.
This ensures that all requests from the user during the session are sent to
the same instance","If your application does not have its own session cookie, then you can
configure Elastic Load Balancing to create a session cookie by specifying
your own stickiness duration.",,,1,AWS Archi Professional,5
"You are deploying your first EC2 instance in AWS and are using the AWS console to do
this. You have chosen your AMI and your instance type and have now come to the screen
where you configure your instance details. One of the things that you need to decide is
whether you want to auto-assign a public IP address or not. You assume that if you do not
choose this option you will be able to assign an Elastic IP address later, which happens to
be a correct assumption. Which of the below options best describes why an Elastic IP
address would be preferable to a public IP address?
Choose the correct option from the below:","An Elastic IP address is free, whilst you must pay for a public IP address.","With an Elastic IP address, you can mask the failure of an instance or
software by rapidly remapping the address to another instance in your
account.","You can have an unlimited amount of Elastic IP addresses, however public
IP addresses are limited in number.","An Elastic IP address cannot be accessed from the internet like a public IP
address and hence is safer from a security standpoint.",,,2,AWS Archi Professional,5
"You have an EBS root device on /dev/sda1 on one of your EC2 instances. You are having
trouble with this particular instance and you want to either Stop/Start, Reboot or
Terminate the instance but you do not want to lose any data that you have stored
on /dev/sda1. Which of the below statements best describes the effect each change of
instance state would have on the data you have stored on /dev/sda1?
Choose the correct option from the below","Whether you stop/start, reboot or terminate the instance it does not matter
because data on an EBS volume is not ephemeral and the data will not be
lost regardless of what method is used","Whether you stop/start, reboot or terminate the instance it does not matter
because data on an EBS volume is ephemeral and it will be lost no matter
what method is used.","If you stop/start the instance the data will not be lost. However, if you
either terminate or reboot the instance the data will be lost.","The data in root EBS volume is not permanent with default setting - it
only persists during the lifetime of the instance. The data will be lost if
you terminate the instance. However, the data will remain
on /dev/sda1 if you reboot or stop/start the instance because data
on an EBS volume is not ephemeral.",,,4,AWS Archi Professional,5
"Someone on your team configured a Virtual Private Cloud with two public subnets in two
separate AZs and two private subnets in two separate AZs. Each public subnet AZ has a
matching private subnet AZ. The VPC and its subnets are properly configured. You also
notice that there are multiple webserver instances in the private subnet, and you've been
charged with setting up a public-facing Elastic Load Balancer which will accept requests
from clients and distribute those requests to the webserver instances. How can you set
this up without making any significant architectural changes?
Choose the correct option from the below:","Select both of the private subnets which contain the webserver instances
when configuring the ELB.","Put the webserver instances in the public subnets and then configure the
ELB with those subnets",Select both of the public subnets when configuring the ELB.,"You can't. Webserver instances must be in public subnets in order for this
to work.",,,3,AWS Archi Professional,5
"A complicated data analysis software has used a standard SQS queue to decouple the
requests from users and the backend processing. The visibility timeout for the queue is set
as 60 seconds. For most cases, the process of messages can finish within 1 minute
successfully. However, for certain new requests, it may take about 100 seconds for the backend to get the job done. These requests are tagged with a specific JSON header by
the frontend already. How should you improve the queue configurations in the best way?","In AWS SQS console, simply change the default visibility timeout from 1
minute to 2 minutes","Use AWS SDK to adjust the visibility timeout to 2 minutes for
messages that contain the specific JSON header.","Change the queue type from standard to FIFO with the default visibility
timeout configured as 2 minutes.","Create a new SQS queue as the dead letter queue. Route these specific
requests to the dead letter queue so that the normal backend process is
not influenced.",,,2,AWS Archi Professional,5
"You have been asked to leverage Amazon VPC EC2 and SQS to implement an application
that submits and receives millions of messages per second to a message queue. You want
to ensure that your application has sufficient bandwidth between your EC2 instances and
SQS. Which option will provide the most scalable solution for communicating between the
application and SQS?","Ensure the application instances are properly configured with an Elastic
Load Balancer","Ensure the application instances are launched in private subnets with the
EBS-optimized option enabled","Ensure the application instances are launched in private subnets with the
associate-public-IP-address=true option enabled. Remove any NAT
instance from the public subnet, if any","Ensure the application instances are launched in public subnets with
an Auto Scaling group and Auto Scaling triggers are configured to
watch the SQS queue size.",,,4,AWS Archi Professional,5
"Your company is migrating an entire project to AWS. However, as certain legacy
databases are too old to be migrated, your team has established two direct connections
(10 gigabit) to link the on-premise data center with various AWS services such as S3, EC2,
Lambda, etc. Your lead asks you to aggregate the two direct connections so that the
bandwidth is increased. Which combination of steps should you take to fulfill this
requirement? (Select TWO)","In AWS Direct Connect console, create a link aggregation group (LAG).","Provision two new connections and associate them with the link
aggregation group.","Associate two existing connections with the LAG in AWS Direct
Connect console","Create an AWS Direct Connect gateway to combine two existing AWS
Direct Connect connections over a private virtual interface.",,,1&3,AWS Archi Professional,5
"In order to keep a dedicated connection and a more consistent network performance,
company ABC has set up 8 active Direct Connections between one of Amazon’s Direct
Connect locations and the company’s colocation environment. The speed of the
connections is 100Mbps for 6 connections and 200Mbps for the other 2 connections. The
company plans to create several link aggregation groups (LAG) for all the connections.
Which configurations are valid? (Select TWO)","One LAG with six 100Mbps connections. One LAG with two 200Mbps
connections.","Two LAGs with three 100Mbps connections each. One LAG with two
200Mbps connections","One LAG with four 100Mbps connections. One LAG with the other two
100Mbps connections. One LAG with two 200Mbps connections.",One LAG with all eight direct connections.,,,2&3,AWS Archi Professional,5
"An organization is planning to use AWS for their production roll out. The organization
wants to implement automation for deployment such that it will automatically create a
LAMP stack, download the latest PHP installable from S3 and setup the ELB.
Which of the below mentioned AWS services meets the requirement for making an
orderly deployment of the software?",AWS Elastic Beanstalk,AWS Cloudfront,AWS Cloudformation,AWS DevOps,,,1,AWS Archi Professional,5
"A customer is running a multi-tier web application farm in a virtual private cloud (VPC) that
is not connected to their corporate network. They are connecting to the VPC over the
Internet to manage all of their Amazon EC2 instances running in both the public and
private subnets. They have only authorized the bastion-security-group with Microsoft
Remote Desktop Protocol (RDP) access to the application instance security groups, but
the company wants to further limit administrative access to all of the instances in the VPC.
Which of the following Bastion deployment scenarios will meet this requirement?","Deploy a Windows Bastion host on the corporate network that has RDP
access to all instances in the VPC.","Deploy a Windows Bastion host with an Elastic IP address in the public
subnet and allow SSH access to the bastion from anywhere.","Deploy a Windows Bastion host with an Elastic IP address in the private
subnet, and restrict RDP access to the bastion from only the corporate
public IP addresses.","Deploy a Windows Bastion host with an auto-assigned Public IP
address in the public subnet, and allow RDP access to the bastion
from only the corporate public IP addresses.",,,4,AWS Archi Professional,5
"Your company has HQ in Tokyo and branch offices all over the world and is using a
logistics software with a multi-regional deployment on AWS in Japan, Europe and USA.
The logistic software has a 3-tier architecture and currently uses MySQL 5.6 for data
persistence. Each region has deployed its own database. In the HQ region you run an
hourly batch process reading data from every region to compute cross-regional reports
that are sent by email to all offices. This batch process must be completed as fast as
possible, to quickly optimize logistics. How do you build the database architecture in order
to meet the requirements?","For each regional deployment, use MySQL on EC2 with a master in the
region and use S3 to copy data files hourly to the HQ region.","For each regional deployment, use MySQL on EC2 with a master in the
region and send hourly EBS snapshots to the HQ region.","For each regional deployment, use RDS MySQL with a master in the region
and send hourly RDS snapshots to the HQ region.","For each regional deployment, use RDS MySQL with a master in the
region and a read replica in the HQ region.","Use Direct Connect to connect all regional MySQL deployments to the HQ
region and reduce network latency for the batch process",,4,AWS Archi Professional,5
"A legacy application with license is attached to a single MAC address. Since an EC2
instance can receive a new MAC address while launching new instances, how can you
ensure that your EC2 instances can maintain a single MAC address for licensing? Choose
the correct option","Create an ENI and assign it to the EC2 instance. The ENI will have a
static MAC address and can be detached and reattached to a new
instance if the current instance becomes unavailable.","Private subnets have static MAC addresses. Launch the EC2 instance in a
private subnet and, if required, use a NAT to serve data over the internet","Configure a manual MAC address for each EC2 instance and report that to
the licensing company.","AWS cannot have a fixed MAC address; the best solution is to create a
dedicated VPN/VGW gateway to serve data from the legacy application",,,1,AWS Archi Professional,5
"A company needs to configure a NAT instance for its internal AWS applications to be able
to download patches and package software. Currently, they are running a NAT instance
that is using the floating IP scripting configuration to create fault tolerance for the NAT.
The NAT instance needs to be built with fault tolerance in mind. What is the best way to
configure the NAT instance with fault tolerance?
Choose the correct answer from the options below:","Create one NAT instance in a public subnet; create a route from the private
subnet to the NAT instance","Create two NAT instances in a public subnet; create a route from the
private subnet to each NAT instance for fault tolerance.","Create a NAT instance in a public subnet with application running in
private subnet in an AZ. Create a similar architecture in another AZ;
create a route from the private subnet to each NAT instance residing
in these AZ's for fault tolerance",Create two NAT instances in two separate private subnets,,,3,AWS Archi Professional,5
"Your company has received a contract to rebuild a legacy enterprise file sharing system
for a large media house. As of now, the company is using an on-premise private file
sharing solution which is integrated with its directory service and uses a web-based intranet application to share files. With growing remote staff the company wants to
migrate the solution to the cloud and also need support for mobile devices so that remote
staff can work offline as well. Please suggest a valid option to architect the system with
given requirements.","Migrate all the files to S3 and build web and mobile applications to support
share the files. Use IAM for user access management.","Migrate the existing system to EC2 with Autoscaling and save all the files to
S3. Use the AD Connector for user access management","Use the AWS WorkDocs and integrate with the on-premise directory
server with AD Connector","Use the Simple AD integration with IAM, and use the bucket level policies
to share files via S3. Enable the S3 Website Hosting for web access.",,,3,AWS Archi Professional,5
"You have a legacy application running that uses an m4.large instance size and cannot
scale with Auto Scaling, but only has peak performance 5% of the time. This is a huge
waste of resources and money so your Senior Technical Manager has set you the task of
trying to reduce costs while still keeping the legacy application running as it should.
Which of the following will best accomplish the task your manager has assigned you?
Choose the correct answer from the options below:",Use a T2 burstable performance instance,Use a C4.large instance with enhanced networking.,Use two t2.nano instances that have single Root I/O Virtualization,Use t2.nano instance and add spot instances when they are required.,,,1,AWS Archi Professional,5
"The Dynamic Host Configuration Protocol (DHCP) provides a standard for passing
configuration information to hosts on a TCP/IP network. You can have multiple sets of
DHCP options, but you can associate only one set of DHCP options with a VPC at a time.
You have just created your first set of DHCP options, associated it with your VPC but now
realize that you have made an error in setting them up and you need to change the
options. Which of the following options do you need to take to achieve this? Choose the
correct answer from the options below","You need to stop all the instances in the VPC. You can then change the
options, and they will take effect when you start the instances",You can modify the options from the console or the CLI.,"You must create a new set of DHCP options and associate them with
your VPC.","You can modify the options from the CLI only, not from the console",,,3,AWS Archi Professional,5
"The company you work for has a huge amount of infrastructure built on AWS. However,
there has been some concerns recently about the security of this infrastructure, and an
external auditor has been given the task of running a thorough check of all of your
company's AWS assets. The auditor will be in the USA while your company's infrastructure
resides in the Asia Pacific (Sydney) region on AWS. Initially, he needs to check all of your
VPC assets, specifically, security groups and NACLs You have been assigned the task of
providing the auditor with a login to be able to do this. Which of the following would be
the best and most secure solution to provide the auditor with so he can begin his initial
investigations? Choose the correct answer from the options below","Create an IAM user tied to an administrator role. Also provide an additional
level of security with MFA.","Give him root access to your AWS Infrastructure, because he is an auditor
he will need access to every service","Create an IAM Role with the read only permissions to access the AWS
VPC infrastructure and assign that role to the auditor","Create an IAM user with full VPC access but set a condition that will not
allow him to modify anything if the request is from any IP other than his
own.",,,3,AWS Archi Professional,5
"In an attempt to cut costs your accounts manager has come to you and tells you that he
thinks that if the company starts to use consolidated billing that it will save some money.
He also wants the billing set up in such a way that it is relatively simple, and it gives
insights into the environment regarding utilization of resources. Which of the following
consolidated billing setups would satisfy your account manager's needs?
Choose two answers from the options below","Use multiple VPC's for different accounts ( eg: sales, marketing etc.)
and tag the resources within the account",Use one Payer Account and no linked accounts,Use one Payer Account and many linked accounts,IAM user access to the Billing and Cost Management console,,,1&3,AWS Archi Professional,5
Which of the following best describes the scaling for WAF?,"The EC2 instance running your WAF software is placed between your
private subnets and any NATed connections to the Internet","The EC2 instance running your WAF software is placed between your
public subnets and your Internet Gateway","The EC2 instance running your WAF software is placed between your
public subnets and your private subnets","The EC2 instance running your WAF software is included in an Auto
Scaling group and placed in between two Elastic load balancers",,,4,AWS Archi Professional,5
"A company is designing a high availability solution for a customer. This customer requires
that their application needs to be able to handle an unexpected amount of load and allow
site visitors to read data from a DynamoDB table, which contains the results of an online
polling system. At any given time as many as 10,000 requests need to be handled by the
application. Given this information, what would be the best and most cost-saving method
for architecting and developing this application? Choose the correct answer from the
options below","Use the JavaScript SDK and build a static HTML page, hosted inside of
an Amazon S3 bucket; use CloudFront and Route 53 to serve the
website, which uses JavaScript client-side language to communicate
with DynamoDB.","Create a CloudFront distribution that serves the HTML web page, but send
the visitors to an Auto Scaling ELB application pointing to EC2 instances","Deploy an Auto Scaling application with Elastic Load Balancer pointing to
EC2 instances that use a server-side SDK to communicate with the
DynamoDB table.","Create a Lambda script which pulls the most recent DynamoDB polling
result and creates a custom HTML page in S3 as per the user request and
use CloudFront and Route 53 to serve the static website.",,,1,AWS Archi Professional,5
"A company is building an AWS Cloud Environment for a financial regulatory firm. Part of
the requirements is being able to monitor all changes in an environment and all traffic sent
to and from the environment. What two steps you need to take to make sure that all the
requirements for monitoring the financial architecture are satisfied?","Configure an IPS/IDS in promiscuous mode, which will listen to all packet
traffic and API changes","Configure an IPS/IDS system, such as Palo Alto Networks, using
promiscous mode that monitors, filters, and alerts of all potential hazard
traffic leaving the VPC.","Configure an IPS/IDS to listen and block all suspected bad traffic
coming into and out of the VPC. Configure CloudTrail with CloudWatch
Logs to monitor all changes within an environment","Configure an IPS/IDS system, such as Palo Alto Networks, that
monitors, filters, and alerts of all potential hazard traffic sent to and
from the VPC.",,,3&4,AWS Archi Professional,5
"You have acquired a new contract from a client to move all of his existing infrastructures
onto AWS. You notice that he is running some of his applications using multicast, and he
needs to keep it running as such when it is migrated to AWS. You discover that multicast
is not available on AWS, as you cannot manage multiple subnets on a single interface on
AWS and a subnet can only belong to one availability zone. Which of the following would
enable you to deploy legacy applications on AWS that require multicast? Choose the
correct answer from the options below",Provide Elastic Network Interfaces between the subnets.,"Create a virtual overlay network that runs on the OS level of the
instance","All of the answers listed will help in deploying applications that require
multicast on AWS.","Create all the subnets on a different VPC and use VPC peering between
them.",,,2,AWS Archi Professional,5
"A company has hired a third-party security auditor, and the auditor needs read-only
access to the required AWS resources and logs of all VPC records and events that will
occur on AWS. How can the company meet the auditor's requirements without
compromising with the security in the AWS environment?
Choose the correct answer from the options below",Create a role that has the required permissions for the auditor,"Create an SNS notification that sends the CloudTrail log files to the
auditor's email when CloudTrail delivers the logs to S3, but do not allow
the auditor access to the AWS environment.","The company should contact AWS as part of the shared responsibility
model, and AWS will grant required access to the third-party auditor","Enable CloudTrail and specify the S3 bucket for your log file delivery.
Create an IAM user who has read only permission to the required AWS
resources including the bucket containing CloudTrail logs",,,4,AWS Archi Professional,5
"After configuring a whole site CDN on CloudFront you receive the following error:
This distribution is not configured to allow the HTTP request method that was used for this
request. The distribution supports only cachable requests.
What is the most likely cause of this?",The CloudFront distribution is configured to the wrong origin,"Allowed HTTP methods on that specific origin is only accepting GET,
HEAD","Allowed HTTP methods on that specific origin is only accepting POST,
PATCH","Allowed HTTP methods on that specific origin is only accepting GET,
HEAD, OPTIONS, PUT, POST, PATCH, DELETE",,,2,AWS Archi Professional,5
"A company is running a MySQL RDS instance inside AWS; however, a new requirement for
disaster recovery is keeping a read replica of the production RDS instance in an onpremise
data center. What is the secure and cost-effective way for performing this
replication? Choose the correct answer from the options below","Configure the RDS instance as the master and enable replication over the
open internet using a secure SSL endpoint to the on-premise server.","RDS cannot replicate to an on-premise database server. Instead, first
configure the RDS instance to replicate to an EC2 instance with core
MySQL, and then configure replication over a secure VPN/VPG connection","Create a Data Pipeline that exports the MySQL data each night and
securely downloads the data from an S3 HTTPS endpoint","Use mysqldump as a backup for Amazon RDS database to external
MySQL database. Create an IPSec VPN connection using VPN/VGW
through Virtual Private Cloud",,,4,AWS Archi Professional,5
"You currently have 9 EC2 instances running in a Placement Group. All these nine instances
were initially launched at the same time and seemed to be performing as expected. You
decide that you need to add two new instances to the group; however, when you attempt
to do this you receive a 'capacity error.' Which of the following actions will most likely fix
this problem? Choose the correct answer from the options below","Create another placement group and launch new instances in that group.
Make sure that both the placement groups are in the same subnet","Stop and restart the instances in the Placement Group and then try the
launch again.","Request a capacity increase from AWS as you are initially limited to 10
instances per Placement Group","Make sure all the instances are the same size and then try the launch
again.",,,2,AWS Archi Professional,5
"An application has multiple components. The single application and all the components
are hosted on a single EC2 instance (without an ELB) in a VPC. You have been told that this
needs to be set up with two separate SSLs for each component. Which of the following
would best achieve the setting up of the two separate SSLs while using still only using
one EC2 instance? Choose the correct answer from the options below","Create an EC2 instance which has multiple network interfaces with
multiple elastic IP addresses","Create an EC2 instance which has both an ACL and the security group
attached to it and have separate rules for each IP address.","Create an EC2 instance which has multiple subnets attached to it and each
will have a separate IP address.",Create an EC2 instance with a NAT address,,,1,AWS Archi Professional,5
